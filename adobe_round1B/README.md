# Adobe PDF Outline Extractor â€“ Hackathon Submission (Round 1A)

## ğŸš€ Overview

- This project extracts structured outlines (headings/sections) from PDFs in multiple languages (English, Chinese, Japanese, Korean, etc.), including support for internal bookmarks, and outputs results as clean JSON.

## ğŸ›  Features

- Accurate heading detection (H1/H2/H3) for English and multilingual (CJK) PDFs
- Handles resumes, forms, research reports, and business documents
- Filters out noise, bullet points, glossary, and non-heading lines
- Merges PDF internal bookmarks (Table of Contents) with visual headings
- **Dockerized** for easy testing (as per hackathon rules)
- Highly configurable and robust across varied PDF layouts

## ğŸ“¥ Input/Output Structure

- Place your PDF files in the `/input` folder.
- Output JSON files will be created in `/output` with the same name as the PDF.

## ğŸ“¦ File List

- `heading_extractor.py` â€“ Main logic for heading extraction
- `extract.py` â€“ Main script for batch-processing PDFs
- `requirements.txt` â€“ Dependencies (`PyMuPDF`, `langdetect`, etc.)
- `Dockerfile` â€“ Containerization
- `/input` â€“ Input PDFs (to be provided by user/judges)
- `/output` â€“ Output JSONs (generated by extractor)
- `README.md` â€“ (This file)

## ğŸ… Bonus Features

- **Multilingual (CJK) Handling:**  
  Automatically detects and extracts headings from Chinese, Japanese, and Korean documents using language detection and CJK-aware rules.
- **PDF Bookmarks Support:**  
  Combines built-in PDF bookmarks (Table of Contents) with extracted headings for extra reliability.
- **Configurable heading rules** (see code comments for easy tweaking).

## ğŸ—ï¸ Usage Instructions

### 1. **Build Docker Image**

```sh
docker build -t pdf-outline-extractor .

Run the extractor (Linux) , use:
docker run --rm -v "$(pwd)/input:/app/input" -v "$(pwd)/output:/app/output" --network none pdf-outline-extractor:latest

On Windows (PowerShell), use:
docker run --rm -v "${PWD}/input:/app/input" -v "${PWD}/output:/app/output" --network none pdf-outline-extractor:latest
```

`Author`

- Name: Swethaswini
- Email: 23z156@psgitech.ac.in

`License`

- This project is licensed under the MIT License â€“ see the LICENSE file for details.

`Acknowledgments`

## PyMuPDF (fitz) for robust PDF parsing.

## langdetect for easy and effective language detection.

## Inspired by Adobe Hackathon and the challenge of real-world PDF extraction!





# Challenge 1b: Multi-Collection PDF Analysis

## Overview

Advanced PDF analysis solution that processes multiple document collections and extracts relevant content based on specific personas and use cases.

## Project Structure

```
Challenge_1b/
â”œâ”€â”€ Collection 1/                    # Travel Planning
â”‚   â”œâ”€â”€ PDFs/                       # South of France guides
â”‚   â”œâ”€â”€ challenge1b_input.json      # Input configuration
â”‚   â””â”€â”€ challenge1b_output.json     # Analysis results
â”œâ”€â”€ Collection 2/                    # Adobe Acrobat Learning
â”‚   â”œâ”€â”€ PDFs/                       # Acrobat tutorials
â”‚   â”œâ”€â”€ challenge1b_input.json      # Input configuration
â”‚   â””â”€â”€ challenge1b_output.json     # Analysis results
â”œâ”€â”€ Collection 3/                    # Recipe Collection
â”‚   â”œâ”€â”€ PDFs/                       # Cooking guides
â”‚   â”œâ”€â”€ challenge1b_input.json      # Input configuration
â”‚   â””â”€â”€ challenge1b_output.json     # Analysis results
â””â”€â”€ README.md
```

## Collections

### Collection 1: Travel Planning

- **Challenge ID**: round_1b_002
- **Persona**: Travel Planner
- **Task**: Plan a 4-day trip for 10 college friends to South of France
- **Documents**: 7 travel guides

### Collection 2: Adobe Acrobat Learning

- **Challenge ID**: round_1b_003
- **Persona**: HR Professional
- **Task**: Create and manage fillable forms for onboarding and compliance
- **Documents**: 15 Acrobat guides

### Collection 3: Recipe Collection

- **Challenge ID**: round_1b_001
- **Persona**: Food Contractor
- **Task**: Prepare vegetarian buffet-style dinner menu for corporate gathering
- **Documents**: 9 cooking guides

## Input/Output Format

### Input JSON Structure

```json
{
  "challenge_info": {
    "challenge_id": "round_1b_XXX",
    "test_case_name": "specific_test_case"
  },
  "documents": [{ "filename": "doc.pdf", "title": "Title" }],
  "persona": { "role": "User Persona" },
  "job_to_be_done": { "task": "Use case description" }
}
```

### Output JSON Structure

```json
{
  "metadata": {
    "input_documents": ["list"],
    "persona": "User Persona",
    "job_to_be_done": "Task description"
  },
  "extracted_sections": [
    {
      "document": "source.pdf",
      "section_title": "Title",
      "importance_rank": 1,
      "page_number": 1
    }
  ],
  "subsection_analysis": [
    {
      "document": "source.pdf",
      "refined_text": "Content",
      "page_number": 1
    }
  ]
}
```

## Key Features

- Persona-based content analysis
- Importance ranking of extracted sections
- Multi-collection document processing
- Structured JSON output with metadata

---

**Note**: This README provides a brief overview of the Challenge 1b solution structure based on available sample data.

`IMPORTANT`

## Run all collections at once

- (Windows):
- With Windows Powershell for Docker.
  \run_all_collections.bat

- (Linux):
- With Linux Powershell for Docker.
  chmod +x run_all_collections.sh

- This will run the extraction for all three collections and update the challenge1b_output.json in each collection directory.

## Manual Docker Run for a Single Collection

` Windows`
docker run --rm ^
-v "%cd%\Collection 1\PDFs:/app/input" ^
-v "%cd%\Collection 1:/app/output" ^
-v "%cd%\Collection 1\challenge1b_input.json:/app/challenge1b_input.json" ^
adobe1b

`Linux`
docker run --rm \
 -v "$(pwd)/Collection 1/PDFs:/app/input" \
  -v "$(pwd)/Collection 1:/app/output" \
 -v "$(pwd)/Collection 1/challenge1b_input.json:/app/challenge1b_input.json" \
 adobe1b

- Change Collection 1 to Collection 2 or Collection 3 as needed.
